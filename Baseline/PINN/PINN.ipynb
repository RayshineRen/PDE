{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../Storage/')\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # 这一行注释掉就是使用gpu，不注释就是使用cpu\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from pyDOE import lhs\n",
    "import time\n",
    "from storage_utils import dumpTotalLoss\n",
    "from log_utils import logTime, logRelativeError\n",
    "from plot_utils import plotting\n",
    "from file_utils import arrangeFiles\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class PhysicsInformedNN:\n",
    "    def __init__(self, X_u, u, X_f, layers, lb, ub, nu, LR):\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "\n",
    "        self.x_u = X_u[:,0:1]\n",
    "        self.t_u = X_u[:,1:2]\n",
    "        self.u = u\n",
    "        self.x_f = X_f[:,0:1]\n",
    "        self.t_f = X_f[:,1:2]\n",
    "        self.layers = layers\n",
    "        self.nu = nu\n",
    "        self.loss_log = []\n",
    "        self.loss_r_log = []\n",
    "        self.loss_b_log = []\n",
    "        self.Nf = X_f.shape[0] - X_u.shape[0]\n",
    "        self.activation = tf.tanh\n",
    "\n",
    "        self.weights, self.biases = self.initilize_NN(layers)\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "\n",
    "        self.x_u_tf = tf.placeholder(tf.float32, shape=[None, self.x_u.shape[1]])\n",
    "        self.t_u_tf = tf.placeholder(tf.float32, shape=[None, self.t_u.shape[1]])\n",
    "        self.u_tf   = tf.placeholder(tf.float32, shape=[None, self.u.shape[1]])\n",
    "        self.x_f_tf = tf.placeholder(tf.float32, shape=[None, self.x_f.shape[1]])\n",
    "        self.t_f_tf = tf.placeholder(tf.float32, shape=[None, self.t_f.shape[1]])\n",
    "\n",
    "        self.u_pred = self.net_u(self.x_u_tf, self.t_u_tf)\n",
    "        self.f_pred = self.net_f(self.x_f_tf, self.t_f_tf)\n",
    "\n",
    "        self.loss_b = tf.reduce_mean(tf.square(self.u_pred - self.u_tf))\n",
    "        self.loss_r = tf.reduce_mean(tf.square(self.f_pred))\n",
    "        self.loss   = self.loss_b + self.loss_r\n",
    "\n",
    "        self.LR = LR\n",
    "        self.optimizer_Adam = tf.train.AdamOptimizer(self.LR)\n",
    "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def initilize_NN(self, layers):\n",
    "        weights = []\n",
    "        biases  = []\n",
    "        num_layers = len(layers)\n",
    "        for l in range(0, num_layers - 1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            weights.append(W)\n",
    "            biases.append(b)\n",
    "        return weights, biases\n",
    "\n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]\n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
    "\n",
    "    def neural_net(self, X, weights, biases):\n",
    "        num_layers = len(weights) + 1\n",
    "        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
    "        for l in range(0, num_layers - 2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = self.activation(tf.add(tf.matmul(H, W), b))\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "        return Y\n",
    "\n",
    "    def net_u(self, x, t):\n",
    "        u = self.neural_net(tf.concat([x,t], 1), self.weights, self.biases)\n",
    "        return u\n",
    "\n",
    "    def net_f(self, x, t):\n",
    "        u = self.net_u(x, t)\n",
    "        u_t = tf.gradients(u, t)[0]\n",
    "        u_x = tf.gradients(u, x)[0]\n",
    "        u_xx = tf.gradients(u_x, x)[0]\n",
    "        f = u_t + u*u_x - self.nu * u_xx\n",
    "        return f\n",
    "\n",
    "    def train(self, nIter=40000, tresh=1e-32):\n",
    "        tf_dict = {self.x_u_tf: self.x_u, self.t_u_tf: self.t_u, self.u_tf: self.u,\n",
    "                   self.x_f_tf: self.x_f, self.t_f_tf: self.t_f}\n",
    "        start_time = time.time()\n",
    "        for it in range(nIter):\n",
    "            self.sess.run(self.train_op_Adam, tf_dict)\n",
    "            loss_value  = self.sess.run(self.loss, tf_dict)\n",
    "            loss_valueb = self.sess.run(self.loss_b, tf_dict)\n",
    "            loss_valuer = self.sess.run(self.loss_r, tf_dict)\n",
    "            self.loss_log.append(loss_value)\n",
    "            self.loss_b_log.append(loss_valueb)\n",
    "            self.loss_r_log.append(loss_valuer)\n",
    "            if loss_value < tresh:\n",
    "                print('It: %d, Loss: %.3e' % (it, loss_value))\n",
    "                break\n",
    "            if it % 2000 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                str_print = 'It: %d, Lossb: %.3e, Lossr: %.3e, Time: %.2f'\n",
    "                print(str_print % (it, loss_valueb, loss_valuer, elapsed))\n",
    "        end_time = time.time()\n",
    "        print(\"training time %f, loss %f\"%(end_time - start_time, loss_value))\n",
    "        self.training_time = end_time - start_time\n",
    "\n",
    "    def predict(self, X_star):\n",
    "        u_star = self.sess.run(self.u_pred, {self.x_u_tf: X_star[:, 0:1], self.t_u_tf:X_star[:, 1:2]})\n",
    "        return u_star"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "iter = 20000\n",
    "nu = 0.01/np.pi\n",
    "noise = 0.0\n",
    "LR = 0.001\n",
    "\n",
    "N_u = 100\n",
    "N_f = 2000\n",
    "layers = [2] + [40] * 5 + [1]\n",
    "path = r'D:\\Documents\\grade4term1\\PDE\\数学基础\\NN\\TF_learn'\n",
    "data = scipy.io.loadmat(path + '/Burgers/burgers_shock.mat')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "x = data['x'].flatten()[:, None]\n",
    "t = data['t'].flatten()[:, None]\n",
    "Exact =np.real(data['usol']).T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "X, T = np.meshgrid(x, t)\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "u_star = Exact.flatten()[:, None]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Doman bounds\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n",
    "# 初始点\n",
    "xx1 = np.hstack((X[0:1,:].T, T[0:1,:].T))\n",
    "uu1 = Exact[0:1,:].T\n",
    "# x=-1的边界点\n",
    "xx2 = np.hstack((X[:,0:1], T[:,0:1]))\n",
    "uu2 = Exact[:,0:1]\n",
    "# x=1的边界点\n",
    "xx3 = np.hstack((X[:,-1:], T[:,-1:]))\n",
    "uu3 = Exact[:,-1:]\n",
    "X_u_train = np.vstack([xx1, xx2, xx3]) #X_u_train.shape=(456, 2)\n",
    "u_train = np.vstack([uu1, uu2, uu3])\n",
    "idx = np.random.choice(X_u_train.shape[0], N_u, replace=False) # 抽取N_u个点\n",
    "X_u_train = X_u_train[idx]\n",
    "u_train = u_train[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def train_f(N_f, iter):\n",
    "    X_f_train = lb + (ub-lb)*lhs(2, N_f)   # pyODE.lhs 拉丁超立方体抽样\n",
    "    X_f_train = np.vstack((X_f_train, X_u_train))\n",
    "    model = PhysicsInformedNN(X_u_train, u_train, X_f_train,\n",
    "                          layers, lb, ub, nu, LR)\n",
    "    model.train(nIter=iter)\n",
    "    u_pred = model.predict(X_star)\n",
    "    error_u = np.linalg.norm(u_star-u_pred, 2)/np.linalg.norm(u_star, 2)\n",
    "    logTime(model)\n",
    "    logRelativeError(model, error_u)\n",
    "    u_pred = u_pred.reshape(-1, 256)\n",
    "    plotting(X, T, Exact, u_pred)\n",
    "    dumpTotalLoss(model)\n",
    "    arrangeFiles(model, iter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0, Lossb: 2.675e-01, Lossr: 9.472e-02, Time: 1.44\n",
      "It: 2000, Lossb: 1.062e-02, Lossr: 3.752e-03, Time: 40.72\n",
      "It: 4000, Lossb: 3.399e-03, Lossr: 2.187e-03, Time: 81.93\n",
      "It: 6000, Lossb: 9.660e-03, Lossr: 1.964e-03, Time: 123.32\n",
      "It: 8000, Lossb: 1.102e-03, Lossr: 5.504e-04, Time: 166.02\n",
      "It: 10000, Lossb: 1.152e-03, Lossr: 2.439e-03, Time: 212.85\n",
      "It: 12000, Lossb: 3.518e-05, Lossr: 1.877e-04, Time: 264.21\n",
      "It: 14000, Lossb: 7.852e-02, Lossr: 5.894e-02, Time: 317.94\n",
      "It: 16000, Lossb: 8.479e-04, Lossr: 5.574e-04, Time: 376.12\n",
      "It: 18000, Lossb: 1.072e-04, Lossr: 1.561e-04, Time: 436.43\n",
      "training time 500.323219, loss 0.000106\n",
      "training time appended done!\n",
      "L2 error appended done!\n",
      "plotting done!\n",
      "dump to .npy done!\n",
      "mkdir done!\n",
      "files moved done!\n",
      "File arranged done!\n",
      "It: 0, Lossb: 2.482e-01, Lossr: 1.720e-03, Time: 1.41\n",
      "It: 2000, Lossb: 1.211e-02, Lossr: 5.132e-03, Time: 95.87\n",
      "It: 4000, Lossb: 3.800e-03, Lossr: 1.891e-03, Time: 196.76\n",
      "It: 6000, Lossb: 2.258e-03, Lossr: 1.558e-03, Time: 294.79\n",
      "It: 8000, Lossb: 1.837e-03, Lossr: 6.303e-04, Time: 389.85\n",
      "It: 10000, Lossb: 1.321e-03, Lossr: 5.928e-04, Time: 483.22\n"
     ]
    }
   ],
   "source": [
    "Nfs = [500, 1000, 2500, 5000, 10000]\n",
    "for N_f in Nfs:\n",
    "    train_f(N_f, iter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}