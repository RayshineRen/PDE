{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../Storage/')\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # 这一行注释掉就是使用gpu，不注释就是使用cpu\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from pyDOE import lhs\n",
    "from storage_utils import dumpTotalLoss\n",
    "from log_utils import logTime, logRelativeError\n",
    "from plot_utils import plotting\n",
    "from file_utils import arrangeFiles\n",
    "from GaussJacobiQuadRule_V3 import Jacobi, DJacobi, GaussLobattoJacobiWeights, GaussJacobiWeights\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class VPINN:\n",
    "    def __init__(self, X_u, u, X_r, X_quad, W_x_quad, \\\n",
    "                 Y_quad, W_y_quad, F_exact_total, grid_x, grid_y, layers, \\\n",
    "                 LR, lossb_weight, lossv_weight, activation):\n",
    "        self.x         = X_u[:, 0:1]\n",
    "        self.y         = X_u[:, 1:2]\n",
    "        self.u         = u\n",
    "        self.x_r       = X_r[:, 0:1]\n",
    "        self.y_r       = X_r[:, 1:2]\n",
    "        self.xquad     = X_quad    # 不需要训练点(xf, f) 只需要求积点和边界点\n",
    "        self.yquad     = Y_quad\n",
    "        self.wquad_x   = W_x_quad\n",
    "        self.wquad_y   = W_y_quad\n",
    "        self.F_ext_total = F_exact_total\n",
    "        self.grid_x    = grid_x\n",
    "        self.grid_y    = grid_y\n",
    "        self.activation= activation\n",
    "        self.NEx       = grid_x.shape[0] - 1\n",
    "        self.NEy       = grid_y.shape[0] - 1\n",
    "        self.loss_log = []\n",
    "        self.loss_r_log = []\n",
    "        self.loss_b_log = []\n",
    "        self.loss_v_log = []\n",
    "        self.Nf = self.Nf = X_r.shape[0] - X_u.shape[0]\n",
    "\n",
    "        self.x_tf   = tf.placeholder(tf.float64, shape=[None, self.x.shape[1]])\n",
    "        self.y_tf   = tf.placeholder(tf.float64, shape=[None, self.y.shape[1]])\n",
    "        self.u_tf   = tf.placeholder(tf.float64, shape=[None, self.u.shape[1]])\n",
    "        self.x_r_tf   = tf.placeholder(tf.float64, shape=[None, self.x_r.shape[1]])\n",
    "        self.y_r_tf   = tf.placeholder(tf.float64, shape=[None, self.y_r.shape[1]])\n",
    "\n",
    "        self.weights, self.biases = self.initialize_NN(layers)\n",
    "        self.u_NN_pred = self.net_u(self.x_tf, self.y_tf)   # 边界点预测值\n",
    "\n",
    "        self.lossb  = tf.reduce_mean(tf.square(self.u_tf - self.u_NN_pred))\n",
    "        self.lossv  = self.variational_loss()\n",
    "        self.lossr  = self.residual_loss(self.x_r_tf, self.y_r_tf)\n",
    "        self.loss   = lossb_weight * self.lossb + lossv_weight * self.lossv + self.lossr\n",
    "\n",
    "        self.LR = LR\n",
    "        self.optimizer_Adam = tf.train.AdamOptimizer(self.LR)\n",
    "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)\n",
    "        self.sess = tf.Session()\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        self.sess.run(self.init)\n",
    "\n",
    "    def initialize_NN(self, layers):\n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers)\n",
    "        for l in range(0,num_layers-1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float64), dtype=tf.float64)\n",
    "            weights.append(W)\n",
    "            biases.append(b)\n",
    "        return weights, biases\n",
    "\n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]\n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim), dtype=np.float64)\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev,dtype=tf.float64), dtype=tf.float64)\n",
    "\n",
    "    def neural_net(self, X, weights, biases):\n",
    "        num_layers = len(weights) + 1\n",
    "        H = X\n",
    "        for l in range(0, num_layers-2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = self.activation(tf.add(tf.matmul(H, W), b))\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "        return Y\n",
    "\n",
    "    def net_u(self, x, y):\n",
    "        u = self.neural_net(tf.concat([x, y], 1), self.weights, self.biases)\n",
    "        return u\n",
    "\n",
    "    def residual_loss(self, x, t):\n",
    "        u = self.net_u(x, t)\n",
    "        u_t = tf.gradients(u, t)[0]\n",
    "        u_x = tf.gradients(u, x)[0]\n",
    "        u_xx = tf.gradients(u_x, x)[0]\n",
    "        f = u_t + u*u_x - 0.01 / np.pi * u_xx\n",
    "        return tf.reduce_mean(tf.square(f))\n",
    "\n",
    "    def net_du(self, x, y):\n",
    "        u    = self.net_u(x, y)\n",
    "        d1ux = tf.gradients(u, x)[0]\n",
    "        d1uy = tf.gradients(u, y)[0]\n",
    "        d2ux = tf.gradients(d1ux, x)[0]\n",
    "        return d1ux, d2ux, d1uy\n",
    "\n",
    "    # 构造测试函数集\n",
    "    def Test_fcn(self, N_test, x):\n",
    "        test_total = []\n",
    "        for n in range(1, N_test+1):\n",
    "            test = Jacobi(n+1, 0, 0, x) - Jacobi(n-1, 0, 0, x)\n",
    "            test_total.append(test)\n",
    "        return np.asarray(test_total)\n",
    "\n",
    "    # variational loss\n",
    "    def variational_loss(self):\n",
    "        varloss_total = 0\n",
    "        for e_y in range(self.NEy):\n",
    "            for e_x in range(self.NEx):\n",
    "                F_ext_element  = self.F_ext_total[e_y*self.NEy + e_x]     # 定位子区域，此形式中F_ext恒0\n",
    "                Ntest_element  = int(np.sqrt(np.shape(F_ext_element)[0])) # 子区域的测试函数个数 x=y\n",
    "                x_quad_element = tf.constant(self.grid_x[e_x] + \\\n",
    "                                 (self.grid_x[e_x + 1] - self.grid_x[e_x])\\\n",
    "                                             / 2*(self.xquad+1))          # 将求积点映射到子区域区间内\n",
    "                jacobian_x     = (self.grid_x[e_x + 1] - self.grid_x[e_x]) / 2  # 系数\n",
    "                # 测试函数及其微分 global(用xquad计算)\n",
    "                testx_quad_element = self.Test_fcn(Ntest_element, self.xquad)\n",
    "\n",
    "                y_quad_element = tf.constant(self.grid_y[e_y] + \\\n",
    "                                 (self.grid_y[e_y + 1] - self.grid_y[e_y]) \\\n",
    "                                             / 2*(self.yquad+1))\n",
    "                jacobian_y     = (self.grid_y[e_y + 1] - self.grid_y[e_y]) / 2\n",
    "                # 测试函数及其微分\n",
    "                testy_quad_element = self.Test_fcn(Ntest_element, self.yquad)\n",
    "                # PDE及其微分\n",
    "                u_NN_quad_element = self.net_u(x_quad_element, y_quad_element)\n",
    "                d1ux_NN_quad_element, d2ux_NN_quad_element, \\\n",
    "                d1uy_NN_quad_element = self.net_du(x_quad_element, y_quad_element)\n",
    "\n",
    "                U_NN_element = []\n",
    "                for phi_y in testy_quad_element:        # 对y积分\n",
    "                    for phi_x in testx_quad_element:    # 对x积分\n",
    "                        inte1_x = jacobian_x*tf.reduce_sum(self.wquad_x*\\\n",
    "                            (d1uy_NN_quad_element + u_NN_quad_element*d1ux_NN_quad_element -\\\n",
    "                             0.01/np.pi*d2ux_NN_quad_element)*phi_x)  # 权函数 * PDE * 测试函数\n",
    "                        inte2_x = jacobian_y*tf.reduce_sum(self.wquad_y*inte1_x*phi_y)\n",
    "                        U_NN_element.append(inte2_x)\n",
    "                U_NN_element = tf.reshape(U_NN_element, (-1, 1))\n",
    "                Res_NN_element = U_NN_element - F_ext_element\n",
    "                loss_element   = tf.reduce_mean(tf.square(Res_NN_element))\n",
    "                varloss_total += loss_element\n",
    "        return varloss_total\n",
    "\n",
    "    def predict(self, x, y):\n",
    "        u_pred  = self.sess.run(self.u_NN_pred, {self.x_tf: x, self.y_tf: y})\n",
    "        return u_pred\n",
    "\n",
    "    def train(self, nIter=40000, tresh=1e-32):\n",
    "        tf_dict = {self.x_tf: self.x, self.y_tf : self.y, self.u_tf: self.u, \\\n",
    "                   self.x_r_tf: self.x_r, self.y_r_tf: self.y_r}\n",
    "        start_time = time.time()\n",
    "        loss_value = 0\n",
    "        for it in range(nIter):\n",
    "            self.sess.run(self.train_op_Adam, tf_dict)\n",
    "            loss_value  = self.sess.run(self.loss, tf_dict)\n",
    "            loss_valueb = self.sess.run(self.lossb, tf_dict)\n",
    "            loss_valuev = self.sess.run(self.lossv, tf_dict)\n",
    "            loss_valuer = self.sess.run(self.lossr, tf_dict)\n",
    "            self.loss_log.append(loss_value)\n",
    "            self.loss_b_log.append(loss_valueb)\n",
    "            self.loss_r_log.append(loss_valuer)\n",
    "            self.loss_v_log.append(loss_valuev)\n",
    "            if loss_value < tresh:\n",
    "                print('It: %d, Loss: %.3e' % (it, loss_value))\n",
    "                break\n",
    "            if it % 1000 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                str_print = 'It: %d, Lossb: %.3e, Lossv: %.3e, Lossr: %.3e, Time: %.2f'\n",
    "                print(str_print % (it, loss_valueb, loss_valuev, loss_valuer, elapsed))\n",
    "        end_time = time.time()\n",
    "        print(\"training time %f, loss %f\"%(end_time - start_time, loss_value))\n",
    "        self.training_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "Opt_Niter = 40000\n",
    "Opt_tresh = 2e-32\n",
    "NEx = 1\n",
    "NEy = 1\n",
    "Net_layer  = [2] + [40] * 5 + [1]\n",
    "activation = tf.tanh\n",
    "Nx_testfcn = 5\n",
    "Ny_testfcn = 5\n",
    "Nx_Quad = 50\n",
    "Ny_Quad = 50\n",
    "lossb_weight = 1\n",
    "lossv_weight = 1\n",
    "N_u = 100\n",
    "N_f = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#++++++++++++++++++++++++++++\n",
    "path = r'D:\\Documents\\grade4term1\\PDE\\数学基础\\NN\\TF_learn'\n",
    "data = scipy.io.loadmat(path + '/Burgers/burgers_shock.mat')\n",
    "x = data['x']\n",
    "t = data['t']\n",
    "Exact =np.real(data['usol']).T\n",
    "X, T = np.meshgrid(x, t)\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "u_star = Exact.flatten()[:, None]\n",
    "#++++++++++++++++++++++++++++\n",
    "# IC / BC points\n",
    "# Doman bounds\n",
    "lb = x_l, y_l = X_star.min(0)\n",
    "ub = x_r, y_h = X_star.max(0)\n",
    "# 初始点\n",
    "xx1 = np.hstack((X[0:1,:].T, T[0:1,:].T))\n",
    "uu1 = Exact[0:1,:].T\n",
    "# x=-1的边界点\n",
    "xx2 = np.hstack((X[:,0:1], T[:, 0:1]))\n",
    "uu2 = Exact[:,0:1]\n",
    "# x=1的边界点\n",
    "xx3 = np.hstack((X[:,-1:], T[:, -1:]))\n",
    "uu3 = Exact[:,-1:]\n",
    "X_u_train = np.vstack([xx1, xx2, xx3])                         #X_u_train.shape=(456, 2)\n",
    "u_train = np.vstack([uu1, uu2, uu3])\n",
    "idx = np.random.choice(X_u_train.shape[0], N_u, replace=False) # 抽取N_u个点\n",
    "X_u_train = X_u_train[idx]\n",
    "u_train = u_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 区域划分\n",
    "delta_x = (x_r - x_l) / NEx\n",
    "# 区域网格点 eg. 均分为两个区域[-1, 0, 1]\n",
    "grid_x  = np.asarray([x_l + i*delta_x for i in range(NEx+1)])\n",
    "# 每个区域内测试函数的数目，目前都一样，结果只取决于区域内的求积点\n",
    "Nx_testfcn_total = np.array((len(grid_x) - 1)*[Nx_testfcn])\n",
    "delta_y = (y_h - y_l) / NEy\n",
    "grid_y  = np.asarray([y_l + i*delta_y for i in range(NEy+1)])\n",
    "Ny_testfcn_total = np.array((len(grid_y) - 1)*[Ny_testfcn])\n",
    "# 计算Fk NEx * NEy 个区域\n",
    "F_ext = np.array((Nx_testfcn * Ny_testfcn) * [0])[:, None]\n",
    "F_ext_total = np.tile(F_ext, (NEx * NEy, 1)).reshape(-1, Nx_testfcn * Ny_testfcn, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#++++++++++++++++++++++++++++\n",
    "# 测试函数迭代 高斯雅各比迭代 测试函数彼此正交 最终总共构造N_testfcn个测试函数\n",
    "def Test_fcn(n, x):\n",
    "   test  = Jacobi(n+1, 0, 0, x) - Jacobi(n-1, 0, 0, x)\n",
    "   return test\n",
    "\n",
    "[x_quad, w_quad_x] = GaussLobattoJacobiWeights(Nx_Quad, 0, 0)\n",
    "[y_quad, w_quad_y] = GaussLobattoJacobiWeights(Ny_Quad, 0, 0)\n",
    "#++++++++++++++++++++++++++++\n",
    "# Quadrature points\n",
    "X_quad   = x_quad[:, None]\n",
    "W_quad_x = w_quad_x[:, None]\n",
    "Y_quad   = y_quad[:, None]\n",
    "W_quad_y = w_quad_y[:, None]\n",
    "#++++++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def train_f(N_f, iter):\n",
    "    X_f_train = lb + (ub - lb)*lhs(2, N_f)\n",
    "    X_f_train = np.vstack((X_f_train, X_u_train))\n",
    "    model = VPINN(X_u_train, u_train, X_f_train, X_quad, W_quad_x, \\\n",
    "              Y_quad, W_quad_y, F_ext_total, grid_x, grid_y, Net_layer, \\\n",
    "              LR, lossb_weight, lossv_weight, activation)\n",
    "    model.train(nIter = iter)\n",
    "    u_pred = model.predict(X_star)\n",
    "    error_u = np.linalg.norm(u_star-u_pred, 2) / np.linalg.norm(u_star, 2)\n",
    "    logTime(model)\n",
    "    logRelativeError(model, error_u)\n",
    "    u_pred = u_pred.reshape(-1, 256)\n",
    "    plotting(X, T, Exact, u_pred)\n",
    "    dumpTotalLoss(model)\n",
    "    arrangeFiles(model, iter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "  Objective function value: 0.000001\n",
      "  Number of iterations: 13112\n",
      "  Number of functions evaluations: 14366\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "  Objective function value: 0.000001\n",
      "  Number of iterations: 0\n",
      "  Number of functions evaluations: 1\n",
      "Training time: 0.0329\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "  Objective function value: 0.000002\n",
      "  Number of iterations: 8669\n",
      "  Number of functions evaluations: 9727\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "  Objective function value: 0.000002\n",
      "  Number of iterations: 0\n",
      "  Number of functions evaluations: 1\n",
      "Training time: 0.0439\n"
     ]
    }
   ],
   "source": [
    "Nfs = [500, 1000, 2500, 5000, 10000]\n",
    "for N_f in Nfs:\n",
    "    train_f(N_f, iter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}