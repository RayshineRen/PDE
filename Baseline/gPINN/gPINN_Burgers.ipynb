{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../Storage/')\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # 这一行注释掉就是使用gpu，不注释就是使用cpu\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from pyDOE import lhs\n",
    "import time\n",
    "from storage_utils import dumpTotalLoss\n",
    "from log_utils import logTime, logRelativeError\n",
    "from plot_utils import plotting\n",
    "from file_utils import arrangeFiles\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class gPINN:\n",
    "    def __init__(self, X_u, u, X_f, layers, lb, ub, nu, W_x, W_t, LR):\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        self.x_u = X_u[:, 0:1]\n",
    "        self.t_u = X_u[:, 1:2]\n",
    "        self.u = u\n",
    "        self.x_f = X_f[:, 0:1]\n",
    "        self.t_f = X_f[:, 1:2]\n",
    "        self.layers = layers\n",
    "        self.nu = nu\n",
    "        self.w_x  = W_x\n",
    "        self.w_t  = W_t\n",
    "        self.loss_log = []\n",
    "        self.loss_r_log = []\n",
    "        self.loss_b_log = []\n",
    "        self.loss_g_log = []\n",
    "        self.Nf = self.Nf = X_f.shape[0] - X_u.shape[0]\n",
    "\n",
    "        self.weights, self.biases = self.initilize_NN(layers)\n",
    "        self.sess = tf.Session()\n",
    "\n",
    "        self.x_u_tf = tf.placeholder(tf.float32, shape=[None, self.x_u.shape[1]])\n",
    "        self.t_u_tf = tf.placeholder(tf.float32, shape=[None, self.t_u.shape[1]])\n",
    "        self.u_tf   = tf.placeholder(tf.float32, shape=[None, self.u.shape[1]])\n",
    "        self.x_f_tf = tf.placeholder(tf.float32, shape=[None, self.x_f.shape[1]])\n",
    "        self.t_f_tf = tf.placeholder(tf.float32, shape=[None, self.t_f.shape[1]])\n",
    "\n",
    "        self.u_pred = self.net_u(self.x_u_tf, self.t_u_tf)\n",
    "        self.f_pred = self.net_f(self.x_f_tf, self.t_f_tf)\n",
    "\n",
    "        self.loss_b = tf.reduce_mean(tf.square(self.u_pred - self.u_tf))\n",
    "        self.loss_r = tf.reduce_mean(tf.square(self.f_pred))\n",
    "        self.loss_g = self.gradient_enhance()\n",
    "        self.loss   = self.loss_b + self.loss_r + self.loss_g\n",
    "\n",
    "        self.LR = LR\n",
    "        self.optimizer_Adam = tf.train.AdamOptimizer(self.LR)\n",
    "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def initilize_NN(self, layers):\n",
    "        weights = []\n",
    "        biases  = []\n",
    "        num_layers = len(layers)\n",
    "        for l in range(0, num_layers - 1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            weights.append(W)\n",
    "            biases.append(b)\n",
    "        return weights, biases\n",
    "\n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]\n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
    "\n",
    "    def neural_net(self, X, weights, biases):\n",
    "        num_layers = len(weights) + 1\n",
    "        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
    "        for l in range(0, num_layers - 2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "        return Y\n",
    "\n",
    "    def net_u(self, x, t):\n",
    "        u = self.neural_net(tf.concat([x,t], 1), self.weights, self.biases)\n",
    "        return u\n",
    "\n",
    "    def net_f(self, x, t):\n",
    "        u = self.net_u(x, t)\n",
    "        u_t = tf.gradients(u, t)[0]\n",
    "        u_x = tf.gradients(u, x)[0]\n",
    "        u_xx = tf.gradients(u_x, x)[0]\n",
    "        f = u_t + u*u_x - self.nu * u_xx\n",
    "        return f\n",
    "\n",
    "    def gradient_enhance(self):\n",
    "        g_x = tf.reduce_mean(tf.square(tf.gradients(self.f_pred, self.x_f_tf)[0]))\n",
    "        g_t = tf.reduce_mean(tf.square(tf.gradients(self.f_pred, self.t_f_tf)[0]))\n",
    "        return self.w_x * g_x + self.w_t * g_t\n",
    "\n",
    "    def train(self, nIter=40000, tresh=1e-32):\n",
    "        tf_dict = {self.x_u_tf: self.x_u, self.t_u_tf: self.t_u, self.u_tf: self.u,\n",
    "                   self.x_f_tf: self.x_f, self.t_f_tf: self.t_f}\n",
    "        start_time = time.time()\n",
    "        loss_value = 0\n",
    "        for it in range(nIter):\n",
    "            self.sess.run(self.train_op_Adam, tf_dict)\n",
    "            loss_value  = self.sess.run(self.loss, tf_dict)\n",
    "            loss_valueb = self.sess.run(self.loss_b, tf_dict)\n",
    "            loss_valueg = self.sess.run(self.loss_g, tf_dict)\n",
    "            loss_valuer = self.sess.run(self.loss_r, tf_dict)\n",
    "            self.loss_log.append(loss_value)\n",
    "            self.loss_b_log.append(loss_valueb)\n",
    "            self.loss_r_log.append(loss_valuer)\n",
    "            self.loss_g_log.append(loss_valueg)\n",
    "            if loss_value < tresh:\n",
    "                print('It: %d, Loss: %.3e' % (it, loss_value))\n",
    "                break\n",
    "            if it % 2000 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                str_print = 'It: %d, Lossb: %.3e, Lossg: %.3e, Lossr: %.3e, Time: %.2f'\n",
    "                print(str_print % (it, loss_valueb, loss_valueg, loss_valuer, elapsed))\n",
    "        end_time = time.time()\n",
    "        print(\"training time %f, loss %f\"%(end_time - start_time, loss_value))\n",
    "        self.training_time = end_time - start_time\n",
    "\n",
    "    def predict(self, X_star):\n",
    "        u_star = self.sess.run(self.u_pred, {self.x_u_tf: X_star[:, 0:1], self.t_u_tf:X_star[:,1:2]})\n",
    "        return u_star"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "nu = 0.01 / np.pi\n",
    "noise = 0.0\n",
    "\n",
    "N_u = 100\n",
    "N_f = 2000\n",
    "LR = 0.001\n",
    "w_x = 0.01\n",
    "w_t = 0.01\n",
    "layers = [2] + [40] * 5 + [1]\n",
    "path = r'D:\\Documents\\grade4term1\\PDE\\数学基础\\NN\\TF_learn'\n",
    "data = scipy.io.loadmat(path + '/Burgers/burgers_shock.mat')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "x = data['x'].flatten()[:, None]\n",
    "t = data['t'].flatten()[:, None]\n",
    "Exact =np.real(data['usol']).T\n",
    "X, T = np.meshgrid(x, t)\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "u_star = Exact.flatten()[:, None]\n",
    "# BC / IC\n",
    "# Doman bounds\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n",
    "# 初始点\n",
    "xx1 = np.hstack((X[0:1,:].T, T[0:1,:].T))\n",
    "uu1 = Exact[0:1,:].T\n",
    "# x=-1的边界点\n",
    "xx2 = np.hstack((X[:,0:1], T[:,0:1]))\n",
    "uu2 = Exact[:,0:1]\n",
    "# x=1的边界点\n",
    "xx3 = np.hstack((X[:,-1:], T[:,-1:]))\n",
    "uu3 = Exact[:,-1:]\n",
    "X_u_train = np.vstack([xx1, xx2, xx3]) #X_u_train.shape=(456, 2)\n",
    "u_train = np.vstack([uu1, uu2, uu3])\n",
    "idx = np.random.choice(X_u_train.shape[0], N_u, replace=False) # 抽取N_u个点\n",
    "X_u_train = X_u_train[idx]\n",
    "u_train = u_train[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def train_f(N_f, iter):\n",
    "    X_f_train = lb + (ub-lb)*lhs(2, N_f)\n",
    "    X_f_train = np.vstack((X_f_train, X_u_train))\n",
    "    model = gPINN(X_u_train, u_train, X_f_train,\n",
    "                layers, lb, ub, nu, w_x, w_t, LR)\n",
    "    model.train(nIter=iter)\n",
    "    u_pred = model.predict(X_star)\n",
    "    error_u = np.linalg.norm(u_star-u_pred, 2)/np.linalg.norm(u_star, 2)\n",
    "    logTime(model)\n",
    "    logRelativeError(model, error_u)\n",
    "    u_pred = u_pred.reshape(-1, 256)\n",
    "    plotting(X, T, Exact, u_pred)\n",
    "    dumpTotalLoss(model)\n",
    "    arrangeFiles(model, iter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Nfs = [500, 1000, 2500, 5000, 10000]\n",
    "for N_f in Nfs:\n",
    "    train_f(N_f, iter)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}