{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # 这一行注释掉就是使用gpu，不注释就是使用cpu\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import scipy.io\n",
    "from pyDOE import lhs\n",
    "from scipy.interpolate import griddata\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class PINN:\n",
    "    def __init__(self, ics_data, bcs_data, res_data, layers, activation, lr):\n",
    "        self.ics_data = ics_data\n",
    "        self.bcs_data = bcs_data\n",
    "        self.res_data = res_data\n",
    "        self.lr = lr\n",
    "        self.activation = activation\n",
    "        self.loss_log = []\n",
    "        self.loss_res_log = []\n",
    "        self.loss_ics_log = []\n",
    "        self.loss_bcs_log = []\n",
    "        # initial neural network\n",
    "        self.weights, self.biases = self.initilize_NN(layers)\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "        # define placeholder\n",
    "        # initial condition\n",
    "        self.u_i_tf  = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "        self.t_i_tf  = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "        self.x_i_tf  = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "        # boundary condition\n",
    "        self.t_b_tf  = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "        self.x_b_tf  = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "        # collocation points\n",
    "        self.t_r_tf  = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "        self.x_r_tf  = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "        # define u, f, residual loss\n",
    "        self.u_res   = self.net_u(self.x_r_tf, self.t_r_tf)\n",
    "        self.f       = self.net_f(self.u_res, self.x_r_tf, self.t_r_tf)\n",
    "        self.loss_res= tf.reduce_mean(tf.square(self.f))\n",
    "        # Dirichlet boundary\n",
    "        self.u_bcs   = self.net_u(self.x_b_tf, self.t_b_tf)\n",
    "        self.loss_bcs= tf.reduce_mean(tf.square(self.u_bcs))\n",
    "        self.u_ics   = self.net_u(self.x_i_tf, self.t_i_tf)\n",
    "        self.loss_ics= tf.reduce_mean(tf.square(self.u_ics - self.u_i_tf))\n",
    "        # total loss function\n",
    "        self.loss    = self.loss_res + self.loss_bcs + self.loss_ics\n",
    "        # define BFGS optimizer\n",
    "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "            self.loss,\n",
    "            method = 'L-BFGS-B',\n",
    "            options = {'maxiter': 20000,\n",
    "                       'maxfun': 50000,\n",
    "                       'maxcor': 50,\n",
    "                       'maxls': 50,\n",
    "                       'ftol' : 1.0 * np.finfo(float).eps}\n",
    "        )\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "    '''\n",
    "    function : initilize_NN\n",
    "    input    : layers  (list)\n",
    "    output   : weights ([tf.Variable]), biases ([tf.Variable])\n",
    "    '''\n",
    "    def initilize_NN(self, layers):\n",
    "        weights = []\n",
    "        biases  = []\n",
    "        num_layers = len(layers)\n",
    "        for l in range(0, num_layers - 1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            weights.append(W)\n",
    "            biases.append(b)\n",
    "        return weights, biases\n",
    "    '''\n",
    "    function : xavier init\n",
    "    input    : size [layer_in, layer_out]\n",
    "    output   : W_in_out (tf.Variable)\n",
    "    '''\n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]\n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
    "    '''\n",
    "    function : neural_net\n",
    "    input    : X -- input of the NN, weights, biases, activation\n",
    "    output   : Y -- output of the NN\n",
    "    '''\n",
    "    def neural_net(self, X, weights, biases, activation):\n",
    "        num_layers = len(weights) + 1\n",
    "        H = X\n",
    "        for l in range(0, num_layers - 2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = activation(tf.add(tf.matmul(H, W), b))\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "        return Y\n",
    "    '''\n",
    "    define u\n",
    "    '''\n",
    "    def net_u(self, x, t):\n",
    "        u = self.neural_net(tf.concat([x, t], 1), self.weights, self.biases, self.activation)\n",
    "        return u\n",
    "    '''\n",
    "    define f (residual loss)\n",
    "    '''\n",
    "    def net_f(self, u, x, t):\n",
    "        u_t  = tf.gradients(u, t)[0]\n",
    "        u_x  = tf.gradients(u, x)[0]\n",
    "        u_xx = tf.gradients(u_x, x)[0]\n",
    "        return u_t + u*u_x - 0.01 / np.pi * u_xx\n",
    "\n",
    "    def train(self, max_iter=40000):\n",
    "        u_i, y_i = self.ics_data.get_batch()\n",
    "        y_b      = self.bcs_data.get_batch()[1]\n",
    "        y_r      = self.res_data.get_batch()[1]\n",
    "        tf_dict = {\n",
    "            self.x_r_tf : y_r[:, 0][:, None],\n",
    "            self.t_r_tf : y_r[:, 1][:, None],\n",
    "            self.x_b_tf : y_b[:, 0][:, None],\n",
    "            self.t_b_tf : y_b[:, 1][:, None],\n",
    "            self.x_i_tf : y_i[:, 0][:, None],\n",
    "            self.t_i_tf : y_i[:, 1][:, None],\n",
    "            self.u_i_tf : u_i\n",
    "        }\n",
    "        self.optimizer.minimize(\n",
    "            self.sess,\n",
    "            feed_dict = tf_dict,\n",
    "            fetches = [self.loss]\n",
    "            # loss_callback = self.callback\n",
    "        )\n",
    "\n",
    "    def predict(self, X_star, T_star):\n",
    "        u_star = self.sess.run(self.u_res, {self.x_r_tf: X_star, self.t_r_tf: T_star})\n",
    "        return u_star"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# generate batch size data\n",
    "class DataGenerator():\n",
    "    def __init__(self, u, y, batch_size):\n",
    "        self.u = u\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def get_batch(self):\n",
    "        N = self.u.shape[0]\n",
    "        index = np.random.randint(0, N, self.batch_size)\n",
    "        u_ = self.u[index, :]\n",
    "        y_ = self.y[index, :]\n",
    "        return u_, y_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat(r\"D:\\Documents\\grade4term1\\PDE\\数学基础\\NN\\TF_learn\\PINN\\appendix\\Data\\burgers_shock.mat\")\n",
    "t = data['t']\n",
    "x = data['x']\n",
    "Exact = np.real(data['usol']).T\n",
    "X, T = np.meshgrid(x, t)\n",
    "X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))\n",
    "u_star = Exact.flatten()[:, None]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "'''\n",
    "Generate ics data & bcs data\n",
    "'''\n",
    "batch_size_ics = 256\n",
    "batch_size_bcs = 100\n",
    "# ics\n",
    "x1 = np.hstack((X[0:1,:].T, T[0:1,:].T))\n",
    "u1 = Exact[0:1,:].T\n",
    "ics_data = DataGenerator(u1, x1, batch_size_ics)\n",
    "# bcs x=-1\n",
    "x2 = np.hstack((X[:,0:1], T[:,0:1]))\n",
    "u2 = Exact[:,0:1]\n",
    "# bcs x=1\n",
    "x3 = np.hstack((X[:,-1:], T[:,-1:]))\n",
    "u3 = Exact[:,-1:]\n",
    "bcs_data = DataGenerator(np.vstack([u2, u3]), np.vstack([x2, x3]), batch_size_bcs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "layers = [2, 32, 32, 32, 32, 32, 1]\n",
    "activation = tf.tanh\n",
    "lr = 1e-3\n",
    "iterations = 20000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Doman bounds\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)\n",
    "def train_model(N_f):\n",
    "    X_f_train = lb + (ub-lb)*lhs(2, N_f) # pyODE.lhs 拉丁超立方体抽样\n",
    "    batch_size_res = N_f\n",
    "    res_data  = DataGenerator(np.zeros((N_f, 1)), X_f_train, batch_size_res)\n",
    "    start_time = time.time()\n",
    "    PINN_tanh = PINN(ics_data, bcs_data, res_data, layers, activation, lr)\n",
    "    print(\"Start training! N_f:%d\"%(N_f))\n",
    "    PINN_tanh.train(iterations)\n",
    "    elapsed = time.time() - start_time\n",
    "    print('Training time: %.4f' % (elapsed))\n",
    "    return PINN_tanh"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def compute_error(model):\n",
    "    u_pred = model.predict(X_star[:, 0][:, None], X_star[:, 1][:, None])\n",
    "    error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "    print('Error u: %e' % (error_u))\n",
    "    return error_u"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Start training! N_f:1500\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "  Objective function value: 0.000014\n",
      "  Number of iterations: 5370\n",
      "  Number of functions evaluations: 5954\n",
      "Training time: 69.5994\n",
      "Error u: 3.006399e-01\n",
      "N_f:1500, error:0.300640\n",
      "Start training! N_f:2000\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "  Objective function value: 0.000016\n",
      "  Number of iterations: 7238\n",
      "  Number of functions evaluations: 7940\n",
      "Training time: 143.8316\n",
      "Error u: 3.270442e-01\n",
      "N_f:2000, error:0.327044\n",
      "Start training! N_f:2500\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "  Objective function value: 0.000009\n",
      "  Number of iterations: 5139\n",
      "  Number of functions evaluations: 5646\n",
      "Training time: 188.1838\n",
      "Error u: 1.818372e-01\n",
      "N_f:2500, error:0.181837\n",
      "Start training! N_f:3000\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "  Objective function value: 0.000032\n",
      "  Number of iterations: 5541\n",
      "  Number of functions evaluations: 6252\n",
      "Training time: 222.7952\n",
      "Error u: 4.498572e-02\n",
      "N_f:3000, error:0.044986\n"
     ]
    }
   ],
   "source": [
    "N_fs = [1500, 2000, 2500, 3000]\n",
    "errors = []\n",
    "for N_f in N_fs:\n",
    "    model = train_model(N_f)\n",
    "    error = compute_error(model)\n",
    "    print(\"N_f:%d, error:%f\"%(N_f, error))\n",
    "    errors.append(error)\n",
    "errors = np.array(errors)\n",
    "np.save('errors_PINN_BFGS.npy', errors)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}