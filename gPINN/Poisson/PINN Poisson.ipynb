{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\programfile\\python3.7.4\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # 这一行注释掉就是使用gpu，不注释就是使用cpu\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class PINN:\n",
    "    def __init__(self, x, layers, activation, lr):\n",
    "        self.x = x\n",
    "        self.lr = lr\n",
    "        self.activation = activation\n",
    "        self.loss_log = []\n",
    "\n",
    "        self.weights, self.biases = self.initilize_NN(layers)\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "        self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x.shape[1]])\n",
    "\n",
    "        self.surrogate_u = self.surrogate(self.x_tf)\n",
    "        self.residual    = self.residual(self.surrogate_u, self.x_tf)\n",
    "        self.loss        = tf.reduce_mean(tf.square(self.residual))\n",
    "\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.lr).minimize(self.loss)\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "    def initilize_NN(self, layers):\n",
    "        weights = []\n",
    "        biases  = []\n",
    "        num_layers = len(layers)\n",
    "        for l in range(0, num_layers - 1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            weights.append(W)\n",
    "            biases.append(b)\n",
    "        return weights, biases\n",
    "\n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]\n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
    "\n",
    "    def neural_net(self, X, weights, biases, activation):\n",
    "        num_layers = len(weights) + 1\n",
    "        H = X\n",
    "        for l in range(0, num_layers - 2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = activation(tf.add(tf.matmul(H, W), b))\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "        return Y\n",
    "\n",
    "    def net_u(self, x):\n",
    "        u = self.neural_net(x, self.weights, self.biases, self.activation)\n",
    "        return u\n",
    "\n",
    "    def surrogate(self, x):\n",
    "        return x*(np.pi - x)*self.net_u(x) + x\n",
    "\n",
    "    def residual(self, u, x):\n",
    "        u_x  = tf.gradients(u, x)[0]\n",
    "        u_xx = tf.gradients(u_x, x)[0]\n",
    "        rhs  = 0\n",
    "        for i in range(1, 5):\n",
    "            rhs += i*tf.sin(i*x)\n",
    "        rhs += 8*tf.sin(8*x)\n",
    "        return u_xx + rhs\n",
    "\n",
    "    def callback(self, loss, res, deriv):\n",
    "        print('Loss:%f,res:%f,deriv:%f'%(loss, res, deriv))\n",
    "\n",
    "    def train(self, max_iter=40000):\n",
    "        loss_value = np.inf\n",
    "        for iter in range(max_iter):\n",
    "            tf_dict = {\n",
    "                self.x_tf:self.x\n",
    "            }\n",
    "            _, loss_value = self.sess.run([self.optimizer,\n",
    "                self.loss], tf_dict)\n",
    "            if iter % 1000 == 0:\n",
    "                print(\"第%d次 %f\"%(iter, loss_value))\n",
    "        print(\"第%d次的损失为%f\"%(max_iter, loss_value))\n",
    "\n",
    "    def predict(self, X_star):\n",
    "        u_star = self.sess.run(self.surrogate_u, {self.x_tf: X_star})\n",
    "        return u_star\n",
    "\n",
    "\n",
    "layers = [1, 20, 20, 20, 20, 1]\n",
    "activation = tf.tanh\n",
    "lr = 1e-3\n",
    "iterations = 20000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def train_model(train_num):\n",
    "    x = np.linspace(0, np.pi, train_num)[:, None]\n",
    "    start_time = time.time()\n",
    "    PINN_tanh = PINN(x, layers, activation, lr)\n",
    "    print(\"Start training! train_num:%d\"%(train_num))\n",
    "    PINN_tanh.train(iterations)\n",
    "    elapsed = time.time() - start_time\n",
    "    print('Training time: %.4f' % (elapsed))\n",
    "    return PINN_tanh"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def compute_error(model, test_num):\n",
    "    x_test   = np.linspace(0, np.pi, test_num)[:, None]\n",
    "    u_test   = x_test\n",
    "    for i in range(1, 5):\n",
    "        u_test += np.sin(i*x_test) / i\n",
    "    u_test  +=  np.sin(8*x_test)/8\n",
    "    u_pred   = model.predict(x_test)\n",
    "    L2_norm  = np.linalg.norm(u_test-u_pred,2)/np.linalg.norm(u_test,2)\n",
    "    return L2_norm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training! train_num:10\n",
      "第0次 43.576332\n",
      "第1000次 5.719227\n",
      "第2000次 0.000000\n",
      "第3000次 0.002690\n",
      "第4000次 0.000000\n",
      "第5000次 0.000076\n",
      "第6000次 0.000005\n",
      "第7000次 0.000000\n",
      "第8000次 0.001367\n",
      "第9000次 0.001697\n",
      "第10000次 0.000028\n",
      "第11000次 0.002833\n",
      "第12000次 0.000317\n",
      "第13000次 0.000006\n",
      "第14000次 0.001033\n",
      "第15000次 0.000358\n",
      "第16000次 0.000048\n",
      "第17000次 0.000006\n",
      "第18000次 0.000003\n",
      "第19000次 0.000020\n",
      "第20000次的损失为0.000160\n",
      "Training time: 236.0724\n",
      "train_num:10, error:0.459955\n",
      "Start training! train_num:11\n",
      "第0次 40.991928\n",
      "第1000次 0.000008\n",
      "第2000次 0.000000\n",
      "第3000次 0.000000\n",
      "第4000次 0.000000\n",
      "第5000次 0.000278\n",
      "第6000次 0.000990\n",
      "第7000次 0.000020\n",
      "第8000次 0.000000\n",
      "第9000次 0.017895\n",
      "第10000次 0.000000\n",
      "第11000次 0.000001\n",
      "第12000次 0.000123\n",
      "第13000次 0.000006\n",
      "第14000次 0.010709\n",
      "第15000次 0.000039\n",
      "第16000次 0.000040\n",
      "第17000次 0.000000\n",
      "第18000次 0.000006\n",
      "第19000次 0.000000\n",
      "第20000次的损失为0.000000\n",
      "Training time: 233.9593\n",
      "train_num:11, error:0.231358\n",
      "Start training! train_num:12\n",
      "第0次 44.690308\n",
      "第1000次 0.000023\n",
      "第2000次 0.000000\n",
      "第3000次 0.000000\n",
      "第4000次 0.000000\n",
      "第5000次 0.000000\n",
      "第6000次 0.000000\n",
      "第7000次 0.000000\n",
      "第8000次 0.000000\n",
      "第9000次 0.000006\n",
      "第10000次 0.000004\n",
      "第11000次 0.000000\n",
      "第12000次 0.000000\n",
      "第13000次 0.000000\n",
      "第14000次 0.000008\n",
      "第15000次 0.000005\n",
      "第16000次 0.007135\n",
      "第17000次 0.000000\n",
      "第18000次 0.000042\n",
      "第19000次 0.014146\n",
      "第20000次的损失为0.000222\n",
      "Training time: 259.5426\n",
      "train_num:12, error:0.419779\n",
      "Start training! train_num:13\n",
      "第0次 43.644512\n",
      "第1000次 0.000572\n",
      "第2000次 0.000000\n",
      "第3000次 0.000000\n",
      "第4000次 0.000000\n",
      "第5000次 0.000000\n",
      "第6000次 0.000000\n",
      "第7000次 0.000191\n",
      "第8000次 0.000000\n",
      "第9000次 0.004503\n",
      "第10000次 0.007882\n",
      "第11000次 0.000003\n",
      "第12000次 0.000317\n",
      "第13000次 0.000123\n",
      "第14000次 0.000000\n",
      "第15000次 0.001949\n",
      "第16000次 0.001131\n",
      "第17000次 0.000029\n",
      "第18000次 0.000083\n",
      "第19000次 0.002775\n",
      "第20000次的损失为0.000005\n",
      "Training time: 255.5321\n",
      "train_num:13, error:0.345536\n",
      "Start training! train_num:14\n",
      "第0次 41.017422\n",
      "第1000次 0.000000\n",
      "第2000次 0.000000\n",
      "第3000次 0.000000\n",
      "第4000次 0.000000\n",
      "第5000次 0.000000\n",
      "第6000次 0.000001\n",
      "第7000次 0.000000\n",
      "第8000次 0.000000\n",
      "第9000次 0.001180\n",
      "第10000次 0.000000\n",
      "第11000次 0.000859\n",
      "第12000次 0.002606\n",
      "第13000次 0.000212\n",
      "第14000次 0.013904\n",
      "第15000次 0.000352\n",
      "第16000次 0.000500\n",
      "第17000次 0.013295\n",
      "第18000次 0.001812\n",
      "第19000次 0.005414\n",
      "第20000次的损失为0.000334\n",
      "Training time: 163.5411\n",
      "train_num:14, error:0.338829\n",
      "Start training! train_num:15\n",
      "第0次 42.833332\n",
      "第1000次 0.014616\n",
      "第2000次 0.000050\n",
      "第3000次 0.000472\n",
      "第4000次 0.003586\n",
      "第5000次 0.000000\n",
      "第6000次 0.000000\n",
      "第7000次 0.000000\n",
      "第8000次 0.000210\n",
      "第9000次 0.000000\n",
      "第10000次 0.000041\n",
      "第11000次 0.000000\n",
      "第12000次 0.002630\n",
      "第13000次 0.000002\n",
      "第14000次 0.000019\n",
      "第15000次 0.000000\n",
      "第16000次 0.000029\n",
      "第17000次 0.002209\n",
      "第18000次 0.001169\n",
      "第19000次 0.000001\n",
      "第20000次的损失为0.000000\n",
      "Training time: 263.4356\n",
      "train_num:15, error:0.353782\n",
      "Start training! train_num:16\n",
      "第0次 45.035465\n",
      "第1000次 0.000094\n",
      "第2000次 0.063342\n",
      "第3000次 0.000000\n",
      "第4000次 0.000002\n",
      "第5000次 0.000000\n",
      "第6000次 0.000059\n",
      "第7000次 0.000030\n",
      "第8000次 0.004040\n",
      "第9000次 0.000064\n",
      "第10000次 0.000010\n",
      "第11000次 0.000279\n",
      "第12000次 0.007176\n",
      "第13000次 0.000001\n",
      "第14000次 0.000039\n",
      "第15000次 0.000098\n",
      "第16000次 0.000019\n",
      "第17000次 0.000000\n",
      "第18000次 0.000252\n",
      "第19000次 0.000258\n",
      "第20000次的损失为0.004241\n",
      "Training time: 266.3898\n",
      "train_num:16, error:0.348441\n",
      "Start training! train_num:17\n",
      "第0次 46.625298\n",
      "第1000次 0.000000\n",
      "第2000次 0.004417\n",
      "第3000次 0.000000\n",
      "第4000次 0.000007\n",
      "第5000次 0.000000\n",
      "第6000次 0.000020\n",
      "第7000次 0.003760\n",
      "第8000次 0.000003\n",
      "第9000次 0.000063\n",
      "第10000次 0.000000\n",
      "第11000次 0.000060\n",
      "第12000次 0.000000\n",
      "第13000次 0.000001\n",
      "第14000次 0.000000\n",
      "第15000次 0.000000\n",
      "第16000次 0.000000\n",
      "第17000次 0.000015\n",
      "第18000次 0.013782\n",
      "第19000次 0.013278\n",
      "第20000次的损失为0.000197\n",
      "Training time: 249.5798\n",
      "train_num:17, error:0.350344\n",
      "Start training! train_num:18\n",
      "第0次 42.371021\n",
      "第1000次 0.000956\n",
      "第2000次 0.000042\n",
      "第3000次 0.000006\n",
      "第4000次 0.000022\n",
      "第5000次 0.003409\n",
      "第6000次 0.000065\n",
      "第7000次 0.000027\n",
      "第8000次 0.004604\n",
      "第9000次 0.000128\n",
      "第10000次 0.000152\n",
      "第11000次 0.000041\n",
      "第12000次 0.002425\n",
      "第13000次 0.000930\n",
      "第14000次 0.000013\n",
      "第15000次 0.019915\n",
      "第16000次 0.000503\n",
      "第17000次 0.000050\n",
      "第18000次 0.005778\n",
      "第19000次 0.001357\n",
      "第20000次的损失为0.000161\n",
      "Training time: 277.3759\n",
      "train_num:18, error:0.349580\n",
      "Start training! train_num:19\n",
      "第0次 46.246964\n",
      "第1000次 0.000000\n",
      "第2000次 0.000000\n",
      "第3000次 0.000000\n",
      "第4000次 0.000000\n",
      "第5000次 0.000000\n",
      "第6000次 0.000005\n",
      "第7000次 0.038262\n",
      "第8000次 0.000005\n",
      "第9000次 0.000000\n",
      "第10000次 0.002239\n",
      "第11000次 0.000000\n",
      "第12000次 0.000392\n",
      "第13000次 0.000000\n",
      "第14000次 0.011446\n",
      "第15000次 0.000000\n",
      "第16000次 0.000350\n",
      "第17000次 0.045302\n",
      "第18000次 0.001696\n",
      "第19000次 0.000211\n",
      "第20000次的损失为0.000143\n",
      "Training time: 296.5324\n",
      "train_num:19, error:0.351378\n",
      "Start training! train_num:20\n",
      "第0次 40.976646\n",
      "第1000次 0.005150\n",
      "第2000次 0.000004\n",
      "第3000次 0.000216\n",
      "第4000次 0.000080\n",
      "第5000次 0.000014\n",
      "第6000次 0.003869\n",
      "第7000次 0.015387\n",
      "第8000次 0.000000\n",
      "第9000次 0.000007\n",
      "第10000次 0.000277\n",
      "第11000次 0.000008\n",
      "第12000次 0.000252\n",
      "第13000次 0.000030\n",
      "第14000次 0.000001\n",
      "第15000次 0.002910\n",
      "第16000次 0.000312\n",
      "第17000次 0.000000\n",
      "第18000次 0.000000\n",
      "第19000次 0.007286\n",
      "第20000次的损失为0.001089\n",
      "Training time: 288.8311\n",
      "train_num:20, error:0.349631\n"
     ]
    }
   ],
   "source": [
    "train_nums = np.arange(10, 21, 1)\n",
    "test_num   = 1000\n",
    "errors     = []\n",
    "for train_num in train_nums:\n",
    "    model = train_model(train_num)\n",
    "    error = compute_error(model, test_num)\n",
    "    print(\"train_num:%d, error:%f\"%(train_num, error))\n",
    "    errors.append(error)\n",
    "errors = np.array(errors)\n",
    "np.save('errors_PINN.npy', errors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors_gNN = np.load('errors_gPINN.npy')\n",
    "errors_NN = np.load('errors_PINN.npy')\n",
    "\n",
    "plt.plot(train_nums, errors_NN, 'b-', label='NN')\n",
    "plt.plot(train_nums, errors_gNN, 'r-', label='gNN')\n",
    "plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('Comparison between NN and gNN L2.pdf')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}